import csv

problem = 'fl'

def train():
    right = []
    wrong = []
    with open(f'./{problem}_right_training.txt') as infile:
        right = infile.readlines()
    with open(f'./{problem}_wrong_training.txt') as infile:
        wrong = infile.readlines()

    # TODO: use training data to calculate and return some bigram probabilities

    # add start and end tokens to each line - This section generated by GitHub Copilot
    right = ['<s> ' + line.strip() + ' </s>' for line in right]
    wrong = ['<s> ' + line.strip() + ' </s>' for line in wrong]

    # this section not generated by GitHub Copilot

    rightBigramCounts = {}
    rightSingleCounts = {}
    rightBigramProbs = {}
    wrongBigramCounts = {}
    wrongSingleCounts = {}
    wrongBigramProbs = {}


    # compute table of bigrams for right and wrong answers - This section mainly generated by GitHub Copilot once I understood how to approach the problem correctly
    # GitHub Copilot helped me count the number of words, word pairs, and the calculation for the bigram probability table.
    # It should be noted that GitHub Copilot did not help me implement the right algorithm for the problem when I was approaching it incorrectly from
    # a code standpoint. I still had to do the work to understand myself how it works by speaking with the professor multiple times and reading the textbook chapter. 
    # It seemed to start helping me more once I implemented the right variables to store the data. Like I've mentioned before, it was used like a calculator to help
    # me implement what I already knew, but faster.

    # right answer bigram calculations
    for line in right:
        words = line.split()
        for i in range(len(words) - 1):
            bigram = words[i] + ' ' + words[i + 1]
            if bigram in rightBigramCounts:
                rightBigramCounts[bigram] += 1
            else:
                rightBigramCounts[bigram] = 1
            firstWord = bigram.split()[0]
            if firstWord in rightSingleCounts:
                rightSingleCounts[firstWord] += 1
            else:
                rightSingleCounts[firstWord] = 1

    for bigram in rightBigramCounts:
        rightBigramProbs[bigram] = rightBigramCounts[bigram] / rightSingleCounts[bigram.split()[0]]

    # wrong answer bigram calculations
    for line in wrong:
        words = line.split()
        for i in range(len(words) - 1):
            bigram = words[i] + ' ' + words[i + 1]
            if bigram in wrongBigramCounts:
                wrongBigramCounts[bigram] += 1
            else:
                wrongBigramCounts[bigram] = 1
            firstWord = bigram.split()[0]
            if firstWord in wrongSingleCounts:
                wrongSingleCounts[firstWord] += 1
            else:
                wrongSingleCounts[firstWord] = 1

 
    for bigram in wrongBigramCounts:
        wrongBigramProbs[bigram] = wrongBigramCounts[bigram] / wrongSingleCounts[bigram.split()[0]]


    return rightBigramProbs, wrongBigramProbs
    



def test(bigrams_right, bigrams_wrong):
    correctly_graded = 0
    incorrectly_graded = 0

    submissions = {}
    with open(f'./{problem}_test_data.csv', newline='') as csvfile:
        reader = csv.reader(csvfile, delimiter=',')
        for row in reader:
            submissions[row[1]] = row[2]
    del submissions['Student.answer']


    # Calculate probability that each answer is right or wrong
    # This section was assisted by GitHub Copilot, but just like before, I had to do the work to understand how to implement it correctly
    # GitHub Copilot helped me with the for loop and the if statements to retrieve the probability of each answer being right or wrong
    # GitHub Copilot didn't seem to be want to help with smoothing. I did that all myself. Also, I evaluated the correctness of each grading myself. 

    for submission, score in submissions.items():
        submission = '<s> ' + submission + ' </s>'
        rightProb = 1
        wrongProb = 1
        words = submission.split()
        for i in range(len(words) - 1):
            bigram = words[i] + ' ' + words[i + 1]
            if bigram in bigrams_right:
                if bigrams_right[bigram] == 0:
                    rightProb *= .5
                else:
                    rightProb *= bigrams_right[bigram]
            if bigram in bigrams_wrong:
                if bigrams_wrong[bigram] == 0:
                    wrongProb *= .5
                else:
                    wrongProb *= bigrams_wrong[bigram]
            
            print(f"rightProb: {rightProb}, wrongProb: {wrongProb}, score: {score}, submission: {submission}")
            
            # check if the grading was correct
            if rightProb > wrongProb:
                if score == '1':
                    correctly_graded += 1
                else:
                    incorrectly_graded += 1
            elif wrongProb > rightProb:
                if score == '0':
                    correctly_graded += 1
                else:
                    incorrectly_graded += 1
            






    print("Number graded correctly: ", correctly_graded)
    print("Number graded incorrectly: ", incorrectly_graded)


if __name__ == '__main__':

    bigrams_right, bigrams_wrong = train()
    test(bigrams_right, bigrams_wrong)
